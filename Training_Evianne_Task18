"""
Created on Sat Mar  9 09:50:46 2019

@author: Evianne
"""

"""
This code gives as output the slices of end-diastolic and end-systolic frames of 100 patients, including both the initial and segmented images.
To know how many slices (N) the patient number X has, use:
N = slice_count[X] - slice_count[X-1]
To get his slice number n (n being a number between 1 and N, including both), use:
Y = output[slice_count[X-1] + n-1]
Then:
Y[0] = patient number
Y[1] = slice number
Y[2] = ED 2D original image
Y[3] = ED 2D ground truth
Y[4] = ES 2D original image
Y[5] = ES 2D ground truth
"""

import os
import numpy as np
import SimpleITK as sitk
import matplotlib.pyplot as plt
import cv2
import math 
import keras
import time
import random

def loadData():
    l=[]
    for i, name in enumerate(os.listdir('Data')):
        data = open('Data\{}\Info.cfg'.format(name), 'r')
        
        ED=data.readline()    #end-diastolic frame information
        for s in ED.split():
            if s.isdigit():   #end-diastolic frame number
                #reading the end-diastolic 3d images:
                if int(s)<10:
                    im_EDframe= sitk.ReadImage('Data\{}\{}_frame0{}.nii.gz'.format(name,name,s))
                    im_EDgt=sitk.ReadImage('Data\{}\{}_frame0{}_gt.nii.gz'.format(name,name,s))
                else:
                    im_EDframe= sitk.ReadImage('Data\{}\{}_frame{}.nii.gz'.format(name,name,s))
                    im_EDgt=sitk.ReadImage('Data\{}\{}_frame{}_gt.nii.gz'.format(name,name,s))
                    
        ES=data.readline()    #end-systolic frame information
        for s in ES.split():
            if s.isdigit():   #end-systolic frame number
                #reading the end-systolic 3d images:
                if int(s)<10:
                    im_ESframe= sitk.ReadImage('Data\{}\{}_frame0{}.nii.gz'.format(name,name,s))
                    im_ESgt=sitk.ReadImage('Data\{}\{}_frame0{}.nii.gz'.format(name,name,s))
                else:
                    im_ESframe= sitk.ReadImage('Data\{}\{}_frame{}.nii.gz'.format(name,name,s))
                    im_ESgt=sitk.ReadImage('Data\{}\{}_frame{}_gt.nii.gz'.format(name,name,s))
                    
        #Converting the 3d images into 3 dimensional arrays:        
        arr_EDframe= sitk.GetArrayFromImage(im_EDframe)
        arr_EDgt= sitk.GetArrayFromImage(im_EDgt)
        arr_ESframe= sitk.GetArrayFromImage(im_ESframe)
        arr_ESgt= sitk.GetArrayFromImage(im_ESgt)
        
        NSlices=arr_EDframe.shape[0]
        
        #l=list with the patient number, the number of slices per frame, and the four 3D frames as arrays
        l.append([i+1, NSlices,arr_EDframe,arr_EDgt,arr_ESframe,arr_ESgt])
        
        
    #output=list with the patient number, the slices number, and the four 2D slices as arrays
    slice_count=[0]
    output=[]
    for i in range(100):
        n=l[i][1]
        for h in range(n):
            output.append([l[i][0],h+1,l[i][2][h],l[i][3][h],l[i][4][h],l[i][5][h]])
            slice_count.append(slice_count[i]+n)
            
    return l, output

#function to calculate distance from coordinates of HoughCircles to center of the image
def calculateDistance(x1,y1,x2,y2):  
    dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)  
    return dist

def cropROI(data, slicenr):
    #input: an array with indices [slicenr, imageX, imageY]
    # slicenr: averaging over this number of slices
    
    LVradius=20 #the radius used in frst, which should be the radius of the LV in the top image
    cropdiam=63 #the length in X and Y direction of the cropped image
    sumdist1 = 0
    sumdist2 = 0
    cropped_output = []
    firstindex = 0
    
    # loop through all patients
    nrpatients = data[len(data)-1][0]
    for j in range(nrpatients):
        # find in the data the index for the first slice of patient j (each slice has an own index)
        for p in range(len(data)):
            if data[p][0]==j:
                firstindex = p
                break  
            
        # loop for partient j over his first slicenr ED slices and calculate Hough Cicles
        for i in range(slicenr):
            EDslice=data[firstindex+i][2]
            center=[EDslice.shape[1]/2,EDslice.shape[0]/2]        #find coordinates of center of image
            im = np.array((EDslice/np.amax(EDslice)) * 255, dtype = np.uint8)
            circles=cv2.HoughCircles(im, cv2.HOUGH_GRADIENT, 1, 70, param1=40, param2=25, minRadius=LVradius-14, maxRadius=LVradius+10)

            #calculate for each of the hough circles the distance to middle point and add for each slice the mindist to sumdist
            dist=[]
            for k in range(circles.shape[1]):
                d=calculateDistance(circles[0,k,0],circles[0,k,1],center[0],center[1])
                dist.append(d)

            mindist=np.argmin(dist)         #find index of minimal distance
            sumdist1 += int(circles[0,mindist,1])
            sumdist2 += int(circles[0,mindist,0])
        
        #Do averaging by deviding the total mindist over the number slicenr
        sumdist1 = int(sumdist1/(slicenr))
        sumdist2 = int(sumdist2/(slicenr))

        #Calculate the total amount of slices per frame for patient j
        for q in range(len(data)):
            if data[q][0] == j+1:
                newindex = q
                break
        nrSlices = newindex - firstindex
        #Loop over all slices of patient j and crop them in the same way
        for m in range(nrSlices):
            ED = data[firstindex+m][2]
            EDgt = data[firstindex+m][3]
            ES = data[firstindex+m][4]
            ESgt = data[firstindex+m][5]
        
            # make the images
            imED = np.array((ED/np.amax(ED)) * 255, dtype = np.uint8)
            imEDgt = np.array((EDgt/np.amax(EDgt)) * 255, dtype = np.uint8)
            imES = np.array((ES/np.amax(ES)) * 255, dtype = np.uint8)
            imESgt = np.array((ESgt/np.amax(ESgt)) * 255, dtype = np.uint8)
            
            #crop the images
            croppedED=imED[sumdist1-cropdiam:sumdist1+cropdiam,sumdist2-cropdiam:sumdist2+cropdiam]
            croppedEDgt=imEDgt[sumdist1-cropdiam:sumdist1+cropdiam,sumdist2-cropdiam:sumdist2+cropdiam]
            croppedES=imES[sumdist1-cropdiam:sumdist1+cropdiam,sumdist2-cropdiam:sumdist2+cropdiam]
            croppedESgt=imESgt[sumdist1-cropdiam:sumdist1+cropdiam,sumdist2-cropdiam:sumdist2+cropdiam]
            
            # save the cropped images in the output list
            cropped_output.append([j,m,croppedED,croppedEDgt,croppedES,croppedESgt])
    
    return cropped_output
#---------------------------------------------------------------------------------------------------
# DEFINING THE NEURAL NETWORK
        
def buildUnet():

    cnn = keras.models.Sequential()

    layer0 = keras.layers.Conv2D(64, (3, 3), activation='relu', strides=1, input_shape=(32, 32, 1))
    cnn.add(layer0)

    layer1 = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)
    cnn.add(layer1)

    layer2 = keras.layers.Conv2D(128, (3, 3), activation='relu', strides=1)
    cnn.add(layer2)

    layer3 = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)
    cnn.add(layer3)

    layer4 = keras.layers.Conv2D(64, (3, 3), activation='relu', strides=1)
    cnn.add(layer4)

    layer5 = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)
    cnn.add(layer5)

    layer6 = keras.layers.Flatten() 
    cnn.add(layer6)

    layer7 = keras.layers.Dense(2, activation='softmax')
    cnn.add(layer7)

    sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.00005, nesterov=False)
    cnn.compile(loss='categorical_crossentropy', optimizer=sgd)
    
    return cnn

#-------------------------------------------------------------------------------------------------
# TRAINING THE NETWORK
    
def make2Dpatches(samples, batch, images, patchsize, label):
    
    halfsize = int(patchsize/2)
    
    X = np.empty([len(batch),patchsize,patchsize,1],dtype=np.float32)
    Y = np.zeros((len(batch),2),dtype=np.int16) 
        
    for i in range(len(batch)):
        
        patch = images[samples[0][batch[i]],(samples[1][batch[i]]-halfsize):(samples[1][batch[i]]+halfsize),(samples[2][batch[i]]-halfsize):(samples[2][batch[i]]+halfsize)]
       
        X[i,:,:,0] = patch
        Y[i,label] = 1 
           
    return X, Y

def make2Dpatchestest(samples, batch, image, patchsize):
    
    halfsize = int(patchsize/2)
    
    X = np.empty([len(batch),patchsize,patchsize,1],dtype=np.float32)
    Y = np.zeros((len(batch),2),dtype=np.int16)
             
    for i in range(len(batch)):
        
        patch = image[(samples[0][batch[i]]-halfsize):(samples[0][batch[i]]+halfsize),(samples[1][batch[i]]-halfsize):(samples[1][batch[i]]+halfsize)]

        X[i,:,:,0] = patch  
        
    return X

#Load data and change output to cropped output
l, output=loadData()
cropped_output = cropROI(output,4)
for i in range(len(cropped_output)):
    if cropped_output[i][2].shape[0]<126 or cropped_output[i][2].shape[1]<126:    #the bigger images have size 512x428
        L0=126-cropped_output[i][2].shape[0]
        L1=126-cropped_output[i][2].shape[1]
        cropped_output[i][2]=np.pad(cropped_output[i][2], ((0,L0),(0,L1)), 'constant', constant_values=0)
        cropped_output[i][3]=np.pad(cropped_output[i][3], ((0,L0),(0,L1)), 'constant', constant_values=0)
        cropped_output[i][4]=np.pad(cropped_output[i][4], ((0,L0),(0,L1)), 'constant', constant_values=0)
        cropped_output[i][5]=np.pad(cropped_output[i][5], ((0,L0),(0,L1)), 'constant', constant_values=0)
# Input
networkpath = r'Networks\trainednetwork.h5'
minibatches = 80
minibatchsize = 50 
patchsize = 32
trainnetwork = True


# Shuffle the data to take a random subset for training later
random.shuffle(cropped_output)

# Split the list l into a list containing all ED frames
EDframes = []
EDground = []
ESframes = []
ESground = []

for i in range(len(cropped_output)):
    EDframes.append(cropped_output[i][2])
    EDground.append(cropped_output[i][3])
    ESframes.append(cropped_output[i][4])
    ESground.append(cropped_output[i][5])

# Take the ES frames and ED frames 
frames = ESframes+EDframes
groundtruth = ESground+EDground

print(frames[0].shape)
print(groundtruth[0].shape)

frames=np.array(frames)
groundtruth=np.array(groundtruth)


#pad the images with zeros to allow patch extraction at all locations
halfsize = int(patchsize/2)    
frames = np.pad(frames,((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)
groundtruth = np.pad(groundtruth,((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)
    
# Split up the data set into a training, test and validation set
Train_frames = frames[:int(len(frames)/2)]
Valid_frames = frames[int(len(frames)/2):int(len(frames)-len(frames)/4)]
Test_frames = frames[int(len(frames)-len(frames)/4):]

Train_frames = np.array(Train_frames)
Valid_frames = np.array(Valid_frames)
Test_frames = np.array(Test_frames)

Train_labels = groundtruth[:int(len(groundtruth)/2)]
Valid_labels = groundtruth[int(len(groundtruth)/2):int(len(groundtruth)-len(groundtruth)/4)]
Test_labels = groundtruth[int(len(groundtruth)-len(groundtruth)/4):]

Train_labels = np.array(Train_labels)
Valid_labels = np.array(Valid_labels)
Test_labels = np.array(Test_labels)

# Initialise the network
cnn = buildUnet()

# Training the network
trainingsamples=np.where(Train_labels==3)
positivesamples = np.nonzero(Train_labels)
negativesamples = np.nonzero(Train_frames-Train_labels)

# Train the network
if trainnetwork:
    losslist = []
    t0 = time.time()

    for i in range(minibatches):
#        # Take random trainingsamples and make the patches
        posbatch = random.sample(list(range(len(positivesamples[0]))),int(minibatchsize/2))
        negbatch = random.sample(list(range(len(negativesamples[0]))),int(minibatchsize/2))
        
        Xpos, Ypos = make2Dpatches(positivesamples,posbatch,Train_frames,patchsize,1) # double patchsize for rotation
        Xneg, Yneg = make2Dpatches(negativesamples,negbatch,Train_frames,patchsize,0)   # it is cropped later
        
        Xtrain = np.vstack((Xpos,Xneg))
        Ytrain = np.vstack((Ypos,Yneg))

        loss = cnn.train_on_batch(Xtrain,Ytrain)
        losslist.append(loss)
        print('Batch: {}'.format(i))
        print('Loss: {}'.format(loss))
        
#        batch = random.sample(list(range(len(trainingsamples[0]))), int(minibatchsize/2))
#        X, Y = make2Dpatches(trainingsamples,batch,frames,patchsize,1)
#        # Train the network and compute the loss
#        loss = cnn.train_on_batch(X,Y)
#        losslist.append(loss)
#        print('Batch: {}'.format(i))
#        print('Loss: {}'.format(loss))

    # Save the network
    cnn.save(networkpath)
    
else:
    # Load the network
    cnn = keras.models.load_model(networkpath)
    
## Validation
#validlosslist = []
#probimage = np.zeros(Valid_frames.shape)


# Loop through all frames in the validation set
#for j in range(np.shape(Valid_frames)[0]):
#    
#    validsamples=np.nonzero(Valid_labels[j])
#
#    probabilities = np.empty((0,))
#        
#    minibatchsize = 100 # Can be set as large as the memory allows
#    
#    for k in range(0,len(validsamples[0]),minibatchsize):
#        print('{}/{} samples labelled'.format(k,len(validsamples[0])))
#        
#        # Determine the batches for the validation
#        if k+minibatchsize < len(validsamples[0]):
#            valbatch = np.arange(k,k+minibatchsize)        
#        else:
#            valbatch = np.arange(k,len(validsamples[0]))        
#        
#        # Make the patches
#        Xval = make2Dpatchestest(validsamples,valbatch,Valid_frames[j],patchsize)
#        
#        # Compute the probability
#        prob = cnn.predict(Xval, batch_size=minibatchsize)
#        probabilities = np.concatenate((probabilities,prob[:,1]))
#    
#    # Compute the loss for the validation        
#    for l in range(minibatches):
#        validloss = cnn.test_on_batch(Xval,prob)
#        validlosslist.append(validloss)
#    
#    # Create the probability image        
#    for m in range(len(validsamples[0])):
#        probimage[validsamples[0][m],validsamples[1][m]] = probabilities[m]
#
## Plot the loss and validation loss         
#plt.close('all')
#plt.figure()
#plt.plot(losslist)  
#plt.plot(validlosslist)
